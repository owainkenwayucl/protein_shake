I0605 15:20:22.277163 139778670391424 xla_bridge.py:906] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory

Running AlphaFold 3. Please note that standard AlphaFold 3 model parameters are
only available under terms of use provided at
https://github.com/google-deepmind/alphafold3/blob/main/WEIGHTS_TERMS_OF_USE.md.
If you do not agree to these terms and are using AlphaFold 3 derived model
parameters, cancel execution of AlphaFold 3 inference with CTRL-C, and do not
use the model parameters.

Found local devices: [RocmDevice(id=0)], using device 0: rocm:0
Building model from scratch...
Checking that model parameters can be loaded...

Running fold job 2PV7...
Output will be written in /root/af_output/2pv7_20250605_152035 since /root/af_output/2pv7 is non-empty.
Running data pipeline...
Running data pipeline for chain A...
I0605 15:20:35.920536 139778670391424 pipeline.py:82] Getting protein MSAs for sequence GMRESYANENQFGFKTINSDIHKIVIVGGYGKLGGLFARYLRASGYPISILDREDWAVAESILANADVVIVSVPINLTLETIERLKPYLTENMLLADLTSVKREPLAKMLEVHTGAVLGLHPMFGADIASMAKQVVVRCDGRFPERYEWLLEQIQIWGAKIYQTNATEHDHNMTYIQALRHFSTFANGLHLSKQPINLANLLALSSPIYRLELAMIGRLFAQDAELYADIIMDKSENLAVIETLKQTYDEALTFFENNDRQGFIDAFHKVRDWFGDYSEQFLKESRQLLQQANDLKQG
I0605 15:20:35.922394 139653252368064 jackhmmer.py:78] Query sequence: GMRESYANENQFGFKTINSDIHKIVIVGGYGKLGGLFARYLRASGYPISILDREDWAVAESILANADVVIVSVPINLTLETIERLKPYLTENMLLADLTSVKREPLAKMLEVHTGAVLGLHPMFGADIASMAKQVVVRCDGRFPERYEWLLEQIQIWGAKIYQTNATEHDHNMTYIQALRHFSTFANGLHLSKQPINLANLLALSSPIYRLELAMIGRLFAQDAELYADIIMDKSENLAVIETLKQTYDEALTFFENNDRQGFIDAFHKVRDWFGDYSEQFLKESRQLLQQANDLKQG
I0605 15:20:35.922866 139653243975360 jackhmmer.py:78] Query sequence: GMRESYANENQFGFKTINSDIHKIVIVGGYGKLGGLFARYLRASGYPISILDREDWAVAESILANADVVIVSVPINLTLETIERLKPYLTENMLLADLTSVKREPLAKMLEVHTGAVLGLHPMFGADIASMAKQVVVRCDGRFPERYEWLLEQIQIWGAKIYQTNATEHDHNMTYIQALRHFSTFANGLHLSKQPINLANLLALSSPIYRLELAMIGRLFAQDAELYADIIMDKSENLAVIETLKQTYDEALTFFENNDRQGFIDAFHKVRDWFGDYSEQFLKESRQLLQQANDLKQG
I0605 15:20:35.923601 139653235582656 jackhmmer.py:78] Query sequence: GMRESYANENQFGFKTINSDIHKIVIVGGYGKLGGLFARYLRASGYPISILDREDWAVAESILANADVVIVSVPINLTLETIERLKPYLTENMLLADLTSVKREPLAKMLEVHTGAVLGLHPMFGADIASMAKQVVVRCDGRFPERYEWLLEQIQIWGAKIYQTNATEHDHNMTYIQALRHFSTFANGLHLSKQPINLANLLALSSPIYRLELAMIGRLFAQDAELYADIIMDKSENLAVIETLKQTYDEALTFFENNDRQGFIDAFHKVRDWFGDYSEQFLKESRQLLQQANDLKQG
I0605 15:20:35.924017 139653252368064 subprocess_utils.py:68] Launching subprocess "/usr/bin/jackhmmer -o /dev/null -A /tmp/tmp5bv96hne/output.sto --noali --F1 0.0005 --F2 5e-05 --F3 5e-07 --cpu 8 -N 1 -E 0.0001 --incE 0.0001 /tmp/tmp5bv96hne/query.fasta /root/public_databases/uniref90_2022_05.fa"
I0605 15:20:35.924106 139653227189952 jackhmmer.py:78] Query sequence: GMRESYANENQFGFKTINSDIHKIVIVGGYGKLGGLFARYLRASGYPISILDREDWAVAESILANADVVIVSVPINLTLETIERLKPYLTENMLLADLTSVKREPLAKMLEVHTGAVLGLHPMFGADIASMAKQVVVRCDGRFPERYEWLLEQIQIWGAKIYQTNATEHDHNMTYIQALRHFSTFANGLHLSKQPINLANLLALSSPIYRLELAMIGRLFAQDAELYADIIMDKSENLAVIETLKQTYDEALTFFENNDRQGFIDAFHKVRDWFGDYSEQFLKESRQLLQQANDLKQG
I0605 15:20:35.924313 139653243975360 subprocess_utils.py:68] Launching subprocess "/usr/bin/jackhmmer -o /dev/null -A /tmp/tmpv5ltj8y0/output.sto --noali --F1 0.0005 --F2 5e-05 --F3 5e-07 --cpu 8 -N 1 -E 0.0001 --incE 0.0001 /tmp/tmpv5ltj8y0/query.fasta /root/public_databases/mgy_clusters_2022_05.fa"
I0605 15:20:35.924788 139653235582656 subprocess_utils.py:68] Launching subprocess "/usr/bin/jackhmmer -o /dev/null -A /tmp/tmphg4pua3d/output.sto --noali --F1 0.0005 --F2 5e-05 --F3 5e-07 --cpu 8 -N 1 -E 0.0001 --incE 0.0001 /tmp/tmphg4pua3d/query.fasta /root/public_databases/bfd-first_non_consensus_sequences.fasta"
I0605 15:20:35.925142 139653227189952 subprocess_utils.py:68] Launching subprocess "/usr/bin/jackhmmer -o /dev/null -A /tmp/tmpz4tfb5w1/output.sto --noali --F1 0.0005 --F2 5e-05 --F3 5e-07 --cpu 8 -N 1 -E 0.0001 --incE 0.0001 /tmp/tmpz4tfb5w1/query.fasta /root/public_databases/uniprot_all_2021_04.fa"
I0605 15:21:42.645128 139653235582656 subprocess_utils.py:97] Finished Jackhmmer (bfd-first_non_consensus_sequences.fasta) in 66.720 seconds
I0605 15:24:50.237776 139653252368064 subprocess_utils.py:97] Finished Jackhmmer (uniref90_2022_05.fa) in 254.314 seconds
I0605 15:27:04.965183 139653227189952 subprocess_utils.py:97] Finished Jackhmmer (uniprot_all_2021_04.fa) in 389.040 seconds
I0605 15:31:45.651733 139653243975360 subprocess_utils.py:97] Finished Jackhmmer (mgy_clusters_2022_05.fa) in 669.727 seconds
I0605 15:31:45.733413 139778670391424 pipeline.py:115] Getting protein MSAs took 669.81 seconds for sequence GMRESYANENQFGFKTINSDIHKIVIVGGYGKLGGLFARYLRASGYPISILDREDWAVAESILANADVVIVSVPINLTLETIERLKPYLTENMLLADLTSVKREPLAKMLEVHTGAVLGLHPMFGADIASMAKQVVVRCDGRFPERYEWLLEQIQIWGAKIYQTNATEHDHNMTYIQALRHFSTFANGLHLSKQPINLANLLALSSPIYRLELAMIGRLFAQDAELYADIIMDKSENLAVIETLKQTYDEALTFFENNDRQGFIDAFHKVRDWFGDYSEQFLKESRQLLQQANDLKQG
I0605 15:31:45.733542 139778670391424 pipeline.py:121] Deduplicating MSAs for sequence GMRESYANENQFGFKTINSDIHKIVIVGGYGKLGGLFARYLRASGYPISILDREDWAVAESILANADVVIVSVPINLTLETIERLKPYLTENMLLADLTSVKREPLAKMLEVHTGAVLGLHPMFGADIASMAKQVVVRCDGRFPERYEWLLEQIQIWGAKIYQTNATEHDHNMTYIQALRHFSTFANGLHLSKQPINLANLLALSSPIYRLELAMIGRLFAQDAELYADIIMDKSENLAVIETLKQTYDEALTFFENNDRQGFIDAFHKVRDWFGDYSEQFLKESRQLLQQANDLKQG
I0605 15:31:45.756669 139778670391424 pipeline.py:134] Deduplicating MSAs took 0.02 seconds for sequence GMRESYANENQFGFKTINSDIHKIVIVGGYGKLGGLFARYLRASGYPISILDREDWAVAESILANADVVIVSVPINLTLETIERLKPYLTENMLLADLTSVKREPLAKMLEVHTGAVLGLHPMFGADIASMAKQVVVRCDGRFPERYEWLLEQIQIWGAKIYQTNATEHDHNMTYIQALRHFSTFANGLHLSKQPINLANLLALSSPIYRLELAMIGRLFAQDAELYADIIMDKSENLAVIETLKQTYDEALTFFENNDRQGFIDAFHKVRDWFGDYSEQFLKESRQLLQQANDLKQG, found 8506 unpaired sequences, 7080 paired sequences
I0605 15:31:45.759520 139778670391424 pipeline.py:40] Getting protein templates for sequence GMRESYANENQFGFKTINSDIHKIVIVGGYGKLGGLFARYLRASGYPISILDREDWAVAESILANADVVIVSVPINLTLETIERLKPYLTENMLLADLTSVKREPLAKMLEVHTGAVLGLHPMFGADIASMAKQVVVRCDGRFPERYEWLLEQIQIWGAKIYQTNATEHDHNMTYIQALRHFSTFANGLHLSKQPINLANLLALSSPIYRLELAMIGRLFAQDAELYADIIMDKSENLAVIETLKQTYDEALTFFENNDRQGFIDAFHKVRDWFGDYSEQFLKESRQLLQQANDLKQG
I0605 15:31:45.826196 139778670391424 subprocess_utils.py:68] Launching subprocess "/usr/bin/hmmbuild --informat stockholm --hand --amino /tmp/tmp9677lk1d/output.hmm /tmp/tmp9677lk1d/query.msa"
I0605 15:31:46.157377 139778670391424 subprocess_utils.py:97] Finished Hmmbuild in 0.331 seconds
I0605 15:31:46.159924 139778670391424 subprocess_utils.py:68] Launching subprocess "/usr/bin/hmmsearch --noali --cpu 8 --F1 0.1 --F2 0.1 --F3 0.1 -E 100 --incE 100 --domE 100 --incdomE 100 -A /tmp/tmpocwz3h4_/output.sto /tmp/tmpocwz3h4_/query.hmm /root/public_databases/pdb_seqres_2022_09_28.fasta"
I0605 15:31:52.278245 139778670391424 subprocess_utils.py:97] Finished Hmmsearch (pdb_seqres_2022_09_28.fasta) in 6.118 seconds
I0605 15:31:52.547104 139778670391424 pipeline.py:52] Getting 4 protein templates took 6.79 seconds for sequence GMRESYANENQFGFKTINSDIHKIVIVGGYGKLGGLFARYLRASGYPISILDREDWAVAESILANADVVIVSVPINLTLETIERLKPYLTENMLLADLTSVKREPLAKMLEVHTGAVLGLHPMFGADIASMAKQVVVRCDGRFPERYEWLLEQIQIWGAKIYQTNATEHDHNMTYIQALRHFSTFANGLHLSKQPINLANLLALSSPIYRLELAMIGRLFAQDAELYADIIMDKSENLAVIETLKQTYDEALTFFENNDRQGFIDAFHKVRDWFGDYSEQFLKESRQLLQQANDLKQG
Running data pipeline for chain A took 676.68 seconds
Running data pipeline for chain B...
Running data pipeline for chain B took 0.05 seconds
Writing model input JSON to /root/af_output/2pv7_20250605_152035/2pv7_data.json
Predicting 3D structure for 2PV7 with 1 seed(s)...
Featurising data with 1 seed(s)...
Featurising data with seed 1.
I0605 15:31:57.105267 139778670391424 pipeline.py:166] processing 2PV7, random_seed=1
I0605 15:31:57.249365 139778670391424 pipeline.py:259] Calculating bucket size for input with 596 tokens.
I0605 15:31:57.249691 139778670391424 pipeline.py:265] Got bucket size 768 for input with 596 tokens, resulting in 172 padded tokens.
Featurising data with seed 1 took 7.26 seconds.
Featurising data with 1 seed(s) took 11.69 seconds.
Running model inference and extracting output structure samples with 1 seed(s)...
Running model inference with seed 1...
Traceback (most recent call last):
  File "/app/alphafold/run_alphafold.py", line 831, in <module>
    app.run(main)
  File "/alphafold3_venv/lib/python3.12/site-packages/absl/app.py", line 308, in run
    _run_main(main, args)
  File "/alphafold3_venv/lib/python3.12/site-packages/absl/app.py", line 254, in _run_main
    sys.exit(main(argv))
             ^^^^^^^^^^
  File "/app/alphafold/run_alphafold.py", line 814, in main
    process_fold_input(
  File "/app/alphafold/run_alphafold.py", line 657, in process_fold_input
    all_inference_results = predict_structure(
                            ^^^^^^^^^^^^^^^^^^
  File "/app/alphafold/run_alphafold.py", line 433, in predict_structure
    result = model_runner.run_inference(example, rng_key)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/alphafold/run_alphafold.py", line 347, in run_inference
    result = self._model(rng_key, featurised_example)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
jaxlib.xla_extension.XlaRuntimeError: UNKNOWN: /alphafold3_venv/lib/python3.12/site-packages/alphafold3/model/scoring/scoring.py:58:16: error: All components of the offset index in a gather op must either be a offset dimension or explicitly collapsed; got len(slice_sizes)=3, output_slice_sizes=2, collapsed_slice_dims=1.: 
  pseudo_beta = xnp.take_along_axis(
               ^
/alphafold3_venv/lib/python3.12/site-packages/alphafold3/model/network/template_modules.py:262:48: note: called from
      pseudo_beta_positions, pseudo_beta_mask = scoring.pseudo_beta_fn(
                                               ^
/alphafold3_venv/lib/python3.12/site-packages/alphafold3/model/network/template_modules.py:336:10: note: called from
    act = construct_input(query_embedding, templates, multichain_mask_2d)
         ^
/alphafold3_venv/lib/python3.12/site-packages/haiku/_src/module.py:305:11: note: called from
    return bound_method(*args, **kwargs)
          ^
/alphafold3_venv/lib/python3.12/site-packages/haiku/_src/module.py:464:12: note: called from
      out = f(*args, **kwargs)
           ^
/alphafold3_venv/lib/python3.12/site-packages/alphafold3/model/network/template_modules.py:182:18: note: called from
      embedding = template_embedder(
                 ^
/alphafold3_venv/lib/python3.12/site-packages/haiku/_src/stateful.py:626:21: note: called from
        carry, out = f(carry, x)
                    ^
/alphafold3_venv/lib/python3.12/site-packages/haiku/_src/stateful.py:643:23: note: called from
  (carry, state), ys = jax.lax.scan(
                      ^
/alphafold3_venv/lib/python3.12/site-packages/alphafold3/model/network/template_modules.py:194:36: note: called from
    summed_template_embeddings, _ = hk.scan(
                                   ^
/alphafold3_venv/lib/python3.12/site-packages/haiku/_src/module.py:305:11: note: called from
    return bound_method(*args, **kwargs)
          ^
/alphafold3_venv/lib/python3.12/site-packages/alphafold3/model/scoring/scoring.py:58:16: note: see current operation: "func.return"(%24) : (tensor<768x1x3xf32>) -> ()
  pseudo_beta = xnp.take_along_axis(
               ^
/alphafold3_venv/lib/python3.12/site-packages/haiku/_src/stateful.py:643:23: error: 'mhlo.while' op can't be translated to XLA HLO
  (carry, state), ys = jax.lax.scan(
                      ^
/alphafold3_venv/lib/python3.12/site-packages/alphafold3/model/network/template_modules.py:194:36: note: called from
    summed_template_embeddings, _ = hk.scan(
                                   ^
/alphafold3_venv/lib/python3.12/site-packages/haiku/_src/module.py:305:11: note: called from
    return bound_method(*args, **kwargs)
          ^
/alphafold3_venv/lib/python3.12/site-packages/haiku/_src/module.py:464:12: note: called from
      out = f(*args, **kwargs)
           ^
/alphafold3_venv/lib/python3.12/site-packages/alphafold3/model/network/evoformer.py:191:19: note: called from
    template_act = template_fn(
                  ^
/alphafold3_venv/lib/python3.12/site-packages/alphafold3/model/network/evoformer.py:281:30: note: called from
      pair_activations, key = self._embed_template_pair(
                             ^
/alphafold3_venv/lib/python3.12/site-packages/haiku/_src/module.py:305:11: note: called from
    return bound_method(*args, **kwargs)
          ^
/alphafold3_venv/lib/python3.12/site-packages/haiku/_src/module.py:464:12: note: called from
      out = f(*args, **kwargs)
           ^
/alphafold3_venv/lib/python3.12/site-packages/alphafold3/model/model.py:279:19: note: called from
      embeddings = embedding_module(
                  ^
/alphafold3_venv/lib/python3.12/site-packages/haiku/_src/stateful.py:677:12: note: called from
      val = body_fun(i, val)
           ^
/alphafold3_venv/lib/python3.12/site-packages/haiku/_src/stateful.py:643:23: note: see current operation: 
%186:63 = "mhlo.while"(%50, %23, %arg195, %arg16, %arg17, %arg18, %arg11, %185, %arg12, %arg13, %176, %arg184, %arg183, %arg185, %arg186, %arg187, %arg188, %arg189, %arg190, %arg191, %arg192, %arg193, %70, %arg14, %arg15, %arg145, %arg146, %arg147, %arg148, %arg149, %arg150, %arg151, %arg152, %arg153, %arg154, %arg155, %arg156, %arg157, %arg158, %arg159, %arg160, %arg161, %arg162, %arg163, %arg164, %arg165, %arg166, %arg167, %arg168, %arg169, %arg170, %arg171, %arg172, %arg173, %arg174, %arg175, %arg176, %arg177, %arg178, %arg179, %arg180, %arg182, %arg181) ({
^bb0(%arg514: tensor<i32>, %arg515: tensor<768x768x64xbf16>, %arg516: tensor<2xui32>, %arg517: tensor<4x768xi32>, %arg518: tensor<4x768x24xi1>, %arg519: tensor<4x768x24x3xf32>, %arg520: tensor<31xi32>, %arg521: tensor<768x768xbf16>, %arg522: tensor<1xf32>, %arg523: tensor<31x8x3xi32>, %arg524: tensor<768x768x128xbf16>, %arg525: tensor<128xf32>, %arg526: tensor<128xf32>, %arg527: tensor<39x64xbf16>, %arg528: tensor<64xbf16>, %arg529: tensor<31x64xbf16>, %arg530: tensor<31x64xbf16>, %arg531: tensor<64xbf16>, %arg532: tensor<64xbf16>, %arg533: tensor<64xbf16>, %arg534: tensor<64xbf16>, %arg535: tensor<128x64xbf16>, %arg536: tensor<768x768xbf16>, %arg537: tensor<6xi32>, %arg538: tensor<6xi32>, %arg539: tensor<2x64xf32>, %arg540: tensor<2x64xf32>, %arg541: tensor<2x64x64xbf16>, %arg542: tensor<2x4x16x64xbf16>, %arg543: tensor<2x64x64xbf16>, %arg544: tensor<2x64x4xbf16>, %arg545: tensor<2x4x16x64xbf16>, %arg546: tensor<2x64x4x16xbf16>, %arg547: tensor<2x64xf32>, %arg548: tensor<2x64xf32>, %arg549: tensor<2x64x64xbf16>, %arg550: tensor<2x4x16x64xbf16>, %arg551: tensor<2x64x64xbf16>, %arg552: tensor<2x64x4xbf16>, %arg553: tensor<2x4x16x64xbf16>, %arg554: tensor<2x64x4x16xbf16>, %arg555: tensor<2x64xf32>, %arg556: tensor<2x64xf32>, %arg557: tensor<2x64x256xbf16>, %arg558: tensor<2x128x64xbf16>, %arg559: tensor<2x64xf32>, %arg560: tensor<2x64xf32>, %arg561: tensor<2x64x128xbf16>, %arg562: tensor<2x64x64xbf16>, %arg563: tensor<2x64xf32>, %arg564: tensor<2x64xf32>, %arg565: tensor<2x64x64xbf16>, %arg566: tensor<2x64x128xbf16>, %arg567: tensor<2x64xf32>, %arg568: tensor<2x64xf32>, %arg569: tensor<2x64x128xbf16>, %arg570: tensor<2x64x64xbf16>, %arg571: tensor<2x64xf32>, %arg572: tensor<2x64xf32>, %arg573: tensor<2x64x64xbf16>, %arg574: tensor<2x64x128xbf16>, %arg575: tensor<64xf32>, %arg576: tensor<64xf32>):
  %872 = "mhlo.constant"() <{value = dense<4> : tensor<i32>}> : () -> tensor<i32>
  %873 = "mhlo.compare"(%arg514, %872) <{compare_type = #mhlo<comparison_type SIGNED>, comparison_direction = #mhlo<comparison_direction LT>}> : (tensor<i32>, tensor<i32>) -> tensor<i1>
  "mhlo.return"(%873) : (tensor<i1>) -> ()
}, {
^bb0(%arg451: tensor<i32>, %arg452: tensor<768x768x64xbf16>, %arg453: tensor<2xui32>, %arg454: tensor<4x768xi32>, %arg455: tensor<4x768x24xi1>, %arg456: tensor<4x768x24x3xf32>, %arg457: tensor<31xi32>, %arg458: tensor<768x768xbf16>, %arg459: tensor<1xf32>, %arg460: tensor<31x8x3xi32>, %arg461: tensor<768x768x128xbf16>, %arg462: tensor<128xf32>, %arg463: tensor<128xf32>, %arg464: tensor<39x64xbf16>, %arg465: tensor<64xbf16>, %arg466: tensor<31x64xbf16>, %arg467: tensor<31x64xbf16>, %arg468: tensor<64xbf16>, %arg469: tensor<64xbf16>, %arg470: tensor<64xbf16>, %arg471: tensor<64xbf16>, %arg472: tensor<128x64xbf16>, %arg473: tensor<768x768xbf16>, %arg474: tensor<6xi32>, %arg475: tensor<6xi32>, %arg476: tensor<2x64xf32>, %arg477: tensor<2x64xf32>, %arg478: tensor<2x64x64xbf16>, %arg479: tensor<2x4x16x64xbf16>, %arg480: tensor<2x64x64xbf16>, %arg481: tensor<2x64x4xbf16>, %arg482: tensor<2x4x16x64xbf16>, %arg483: tensor<2x64x4x16xbf16>, %arg484: tensor<2x64xf32>, %arg485: tensor<2x64xf32>, %arg486: tensor<2x64x64xbf16>, %arg487: tensor<2x4x16x64xbf16>, %arg488: tensor<2x64x64xbf16>, %arg489: tensor<2x64x4xbf16>, %arg490: tensor<2x4x16x64xbf16>, %arg491: tensor<2x64x4x16xbf16>, %arg492: tensor<2x64xf32>, %arg493: tensor<2x64xf32>, %arg494: tensor<2x64x256xbf16>, %arg495: tensor<2x128x64xbf16>, %arg496: tensor<2x64xf32>, %arg497: tensor<2x64xf32>, %arg498: tensor<2x64x128xbf16>, %arg499: tensor<2x64x64xbf16>, %arg500: tensor<2x64xf32>, %arg501: tensor<2x64xf32>, %arg502: tensor<2x64x64xbf16>, %arg503: tensor<2x64x128xbf16>, %arg504: tensor<2x64xf32>, %arg505: tensor<2x64xf32>, %arg506: tensor<2x64x128xbf16>, %arg507: tensor<2x64x64xbf16>, %arg508: tensor<2x64xf32>, %arg509: tensor<2x64xf32>, %arg510: tensor<2x64x64xbf16>, %arg511: tensor<2x64x128xbf16>, %arg512: tensor<64xf32>, %arg513: tensor<64xf32>):
  %852 = "mhlo.constant"() <{value = dense<1> : tensor<i32>}> : () -> tensor<i32>
  %853 = "mhlo.constant"() <{value = dense<4> : tensor<i32>}> : () -> tensor<i32>
  %854 = "mhlo.constant"() <{value = dense<0> : tensor<i32>}> : () -> tensor<i32>
  %855 = "mhlo.compare"(%arg451, %854) <{compare_type = #mhlo<comparison_type SIGNED>, comparison_direction = #mhlo<comparison_direction LT>}> : (tensor<i32>, tensor<i32>) -> tensor<i1>
  %856 = "mhlo.add"(%arg451, %853) : (tensor<i32>, tensor<i32>) -> tensor<i32>
  %857 = "mhlo.select"(%855, %856, %arg451) : (tensor<i1>, tensor<i32>, tensor<i32>) -> tensor<i32>
  %858 = "mhlo.dynamic_slice"(%arg454, %857, %854) <{slice_sizes = dense<[1, 768]> : tensor<2xi64>}> : (tensor<4x768xi32>, tensor<i32>, tensor<i32>) -> tensor<1x768xi32>
  %859 = "mhlo.reshape"(%858) : (tensor<1x768xi32>) -> tensor<768xi32>
  %860 = "mhlo.compare"(%arg451, %854) <{compare_type = #mhlo<comparison_type SIGNED>, comparison_direction = #mhlo<comparison_direction LT>}> : (tensor<i32>, tensor<i32>) -> tensor<i1>
  %861 = "mhlo.add"(%arg451, %853) : (tensor<i32>, tensor<i32>) -> tensor<i32>
  %862 = "mhlo.select"(%860, %861, %arg451) : (tensor<i1>, tensor<i32>, tensor<i32>) -> tensor<i32>
  %863 = "mhlo.dynamic_slice"(%arg455, %862, %854, %854) <{slice_sizes = dense<[1, 768, 24]> : tensor<3xi64>}> : (tensor<4x768x24xi1>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<1x768x24xi1>
  %864 = "mhlo.reshape"(%863) : (tensor<1x768x24xi1>) -> tensor<768x24xi1>
  %865 = "mhlo.compare"(%arg451, %854) <{compare_type = #mhlo<comparison_type SIGNED>, comparison_direction = #mhlo<comparison_direction LT>}> : (tensor<i32>, tensor<i32>) -> tensor<i1>
  %866 = "mhlo.add"(%arg451, %853) : (tensor<i32>, tensor<i32>) -> tensor<i32>
  %867 = "mhlo.select"(%865, %866, %arg451) : (tensor<i1>, tensor<i32>, tensor<i32>) -> tensor<i32>
  %868 = "mhlo.dynamic_slice"(%arg456, %867, %854, %854, %854) <{slice_sizes = dense<[1, 768, 24, 3]> : tensor<4xi64>}> : (tensor<4x768x24x3xf32>, tensor<i32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<1x768x24x3xf32>
  %869 = "mhlo.reshape"(%868) : (tensor<1x768x24x3xf32>) -> tensor<768x24x3xf32>
  %870:2 = "func.call"(%arg457, %arg458, %arg459, %arg460, %arg461, %arg462, %arg463, %arg464, %arg465, %arg466, %arg467, %arg468, %arg469, %arg470, %arg471, %arg472, %arg473, %arg474, %arg475, %arg476, %arg477, %arg478, %arg479, %arg480, %arg481, %arg482, %arg483, %arg484, %arg485, %arg486, %arg487, %arg488, %arg489, %arg490, %arg491, %arg492, %arg493, %arg494, %arg495, %arg496, %arg497, %arg498, %arg499, %arg500, %arg501, %arg502, %arg503, %arg504, %arg505, %arg506, %arg507, %arg508, %arg509, %arg510, %arg511, %arg512, %arg513, %arg452, %arg453, %859, %864, %869) <{callee = @None_14}> : (tensor<31xi32>, tensor<768x768xbf16>, tensor<1xf32>, tensor<31x8x3xi32>, tensor<768x768x128xbf16>, tensor<128xf32>, tensor<128xf32>, tensor<39x64xbf16>, tensor<64xbf16>, tensor<31x64xbf16>, tensor<31x64xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<128x64xbf16>, tensor<768x768xbf16>, tensor<6xi32>, tensor<6xi32>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x64xbf16>, tensor<2x4x16x64xbf16>, tensor<2x64x64xbf16>, tensor<2x64x4xbf16>, tensor<2x4x16x64xbf16>, tensor<2x64x4x16xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x64xbf16>, tensor<2x4x16x64xbf16>, tensor<2x64x64xbf16>, tensor<2x64x4xbf16>, tensor<2x4x16x64xbf16>, tensor<2x64x4x16xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x256xbf16>, tensor<2x128x64xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x128xbf16>, tensor<2x64x64xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x64xbf16>, tensor<2x64x128xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x128xbf16>, tensor<2x64x64xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x64xbf16>, tensor<2x64x128xbf16>, tensor<64xf32>, tensor<64xf32>, tensor<768x768x64xbf16>, tensor<2xui32>, tensor<768xi32>, tensor<768x24xi1>, tensor<768x24x3xf32>) -> (tensor<768x768x64xbf16>, tensor<2xui32>)
  %871 = "mhlo.add"(%arg451, %852) : (tensor<i32>, tensor<i32>) -> tensor<i32>
  "mhlo.return"(%871, %870#0, %870#1, %arg454, %arg455, %arg456, %arg457, %arg458, %arg459, %arg460, %arg461, %arg462, %arg463, %arg464, %arg465, %arg466, %arg467, %arg468, %arg469, %arg470, %arg471, %arg472, %arg473, %arg474, %arg475, %arg476, %arg477, %arg478, %arg479, %arg480, %arg481, %arg482, %arg483, %arg484, %arg485, %arg486, %arg487, %arg488, %arg489, %arg490, %arg491, %arg492, %arg493, %arg494, %arg495, %arg496, %arg497, %arg498, %arg499, %arg500, %arg501, %arg502, %arg503, %arg504, %arg505, %arg506, %arg507, %arg508, %arg509, %arg510, %arg511, %arg512, %arg513) : (tensor<i32>, tensor<768x768x64xbf16>, tensor<2xui32>, tensor<4x768xi32>, tensor<4x768x24xi1>, tensor<4x768x24x3xf32>, tensor<31xi32>, tensor<768x768xbf16>, tensor<1xf32>, tensor<31x8x3xi32>, tensor<768x768x128xbf16>, tensor<128xf32>, tensor<128xf32>, tensor<39x64xbf16>, tensor<64xbf16>, tensor<31x64xbf16>, tensor<31x64xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<128x64xbf16>, tensor<768x768xbf16>, tensor<6xi32>, tensor<6xi32>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x64xbf16>, tensor<2x4x16x64xbf16>, tensor<2x64x64xbf16>, tensor<2x64x4xbf16>, tensor<2x4x16x64xbf16>, tensor<2x64x4x16xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x64xbf16>, tensor<2x4x16x64xbf16>, tensor<2x64x64xbf16>, tensor<2x64x4xbf16>, tensor<2x4x16x64xbf16>, tensor<2x64x4x16xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x256xbf16>, tensor<2x128x64xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x128xbf16>, tensor<2x64x64xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x64xbf16>, tensor<2x64x128xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x128xbf16>, tensor<2x64x64xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x64xbf16>, tensor<2x64x128xbf16>, tensor<64xf32>, tensor<64xf32>) -> ()
}) : (tensor<i32>, tensor<768x768x64xbf16>, tensor<2xui32>, tensor<4x768xi32>, tensor<4x768x24xi1>, tensor<4x768x24x3xf32>, tensor<31xi32>, tensor<768x768xbf16>, tensor<1xf32>, tensor<31x8x3xi32>, tensor<768x768x128xbf16>, tensor<128xf32>, tensor<128xf32>, tensor<39x64xbf16>, tensor<64xbf16>, tensor<31x64xbf16>, tensor<31x64xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<128x64xbf16>, tensor<768x768xbf16>, tensor<6xi32>, tensor<6xi32>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x64xbf16>, tensor<2x4x16x64xbf16>, tensor<2x64x64xbf16>, tensor<2x64x4xbf16>, tensor<2x4x16x64xbf16>, tensor<2x64x4x16xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x64xbf16>, tensor<2x4x16x64xbf16>, tensor<2x64x64xbf16>, tensor<2x64x4xbf16>, tensor<2x4x16x64xbf16>, tensor<2x64x4x16xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x256xbf16>, tensor<2x128x64xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x128xbf16>, tensor<2x64x64xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x64xbf16>, tensor<2x64x128xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x128xbf16>, tensor<2x64x64xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x64xbf16>, tensor<2x64x128xbf16>, tensor<64xf32>, tensor<64xf32>) -> (tensor<i32>, tensor<768x768x64xbf16>, tensor<2xui32>, tensor<4x768xi32>, tensor<4x768x24xi1>, tensor<4x768x24x3xf32>, tensor<31xi32>, tensor<768x768xbf16>, tensor<1xf32>, tensor<31x8x3xi32>, tensor<768x768x128xbf16>, tensor<128xf32>, tensor<128xf32>, tensor<39x64xbf16>, tensor<64xbf16>, tensor<31x64xbf16>, tensor<31x64xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<128x64xbf16>, tensor<768x768xbf16>, tensor<6xi32>, tensor<6xi32>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x64xbf16>, tensor<2x4x16x64xbf16>, tensor<2x64x64xbf16>, tensor<2x64x4xbf16>, tensor<2x4x16x64xbf16>, tensor<2x64x4x16xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x64xbf16>, tensor<2x4x16x64xbf16>, tensor<2x64x64xbf16>, tensor<2x64x4xbf16>, tensor<2x4x16x64xbf16>, tensor<2x64x4x16xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x256xbf16>, tensor<2x128x64xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x128xbf16>, tensor<2x64x64xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x64xbf16>, tensor<2x64x128xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x128xbf16>, tensor<2x64x64xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x64xbf16>, tensor<2x64x128xbf16>, tensor<64xf32>, tensor<64xf32>)
  (carry, state), ys = jax.lax.scan(
                      ^
/alphafold3_venv/lib/python3.12/site-packages/haiku/_src/stateful.py:697:15: error: 'mhlo.while' op can't be translated to XLA HLO
  state, val = jax.lax.fori_loop(lower, upper, pure_body_fun, init_val)
              ^
/alphafold3_venv/lib/python3.12/site-packages/alphafold3/model/model.py:306:22: note: called from
      embeddings, _ = hk.fori_loop(0, num_iter, recycle_body, (embeddings, key))
                     ^
/alphafold3_venv/lib/python3.12/site-packages/haiku/_src/module.py:305:11: note: called from
    return bound_method(*args, **kwargs)
          ^
/alphafold3_venv/lib/python3.12/site-packages/haiku/_src/module.py:464:12: note: called from
      out = f(*args, **kwargs)
           ^
/app/alphafold/run_alphafold.py:330:13: note: called from
      return model.Model(self._model_config)(batch)
            ^
/alphafold3_venv/lib/python3.12/site-packages/haiku/_src/transform.py:456:14: note: called from
        out = f(*args, **kwargs)
             ^
/alphafold3_venv/lib/python3.12/site-packages/haiku/_src/transform.py:183:17: note: called from
    out, state = f.apply(params, None, *args, **kwargs)
                ^
/app/alphafold/run_alphafold.py:347:13: note: called from
    result = self._model(rng_key, featurised_example)
            ^
/app/alphafold/run_alphafold.py:433:13: note: called from
    result = model_runner.run_inference(example, rng_key)
            ^
/app/alphafold/run_alphafold.py:657:28: note: called from
    all_inference_results = predict_structure(
                           ^
/alphafold3_venv/lib/python3.12/site-packages/haiku/_src/stateful.py:697:15: note: see current operation: 
%277:192 = "mhlo.while"(%48, %arg67, %arg68, %arg69, %arg70, %arg71, %arg72, %arg73, %arg74, %arg75, %arg76, %arg77, %arg78, %arg79, %arg80, %arg81, %arg82, %arg83, %arg84, %arg85, %arg86, %arg87, %arg88, %arg89, %arg90, %arg91, %arg92, %arg93, %arg94, %arg95, %arg96, %arg97, %arg98, %arg99, %arg100, %arg101, %arg102, %arg103, %arg104, %arg105, %arg106, %arg107, %arg108, %arg109, %arg110, %arg111, %arg112, %arg113, %arg114, %arg115, %arg116, %arg117, %arg118, %arg119, %arg120, %arg121, %arg122, %arg123, %arg124, %arg125, %arg126, %arg127, %arg128, %arg129, %arg130, %arg131, %arg132, %arg133, %arg134, %arg135, %arg136, %arg137, %arg138, %arg139, %arg140, %arg141, %arg142, %arg143, %arg144, %arg145, %arg146, %arg147, %arg148, %arg149, %arg150, %arg151, %arg152, %arg153, %arg154, %arg155, %arg156, %arg157, %arg158, %arg159, %arg160, %arg161, %arg162, %arg163, %arg164, %arg165, %arg166, %arg167, %arg168, %arg169, %arg170, %arg171, %arg172, %arg173, %arg174, %arg175, %arg176, %arg177, %arg178, %arg179, %arg180, %arg181, %arg182, %arg183, %arg184, %arg185, %arg186, %arg187, %arg188, %arg189, %arg190, %arg191, %arg192, %arg193, %arg194, %arg195, %arg196, %arg197, %arg198, %arg199, %arg200, %arg201, %arg202, %arg203, %arg204, %arg205, %arg206, %arg207, %arg208, %arg209, %arg210, %arg211, %arg212, %arg213, %arg214, %arg215, %arg216, %arg217, %arg218, %arg219, %arg220, %arg221, %arg222, %arg223, %arg224, %arg225, %arg226, %arg227, %arg228, %arg229, %arg230, %arg231, %arg232, %arg233, %arg234, %274, %276, %18, %16, %271, %55, %271, %arg417, %arg398, %arg416, %arg426, %arg401, %arg418, %arg432, %arg431, %arg430, %arg429, %arg419, %arg420, %arg421, %arg403, %arg402, %arg399) ({
^bb0(%arg1099: tensor<i32>, %arg1100: tensor<4x64xf32>, %arg1101: tensor<4x64xf32>, %arg1102: tensor<4x64x64xbf16>, %arg1103: tensor<4x64x64xbf16>, %arg1104: tensor<4x128x8xbf16>, %arg1105: tensor<4x128xf32>, %arg1106: tensor<4x128xf32>, %arg1107: tensor<4x64x8x8xbf16>, %arg1108: tensor<4x64xf32>, %arg1109: tensor<4x64xf32>, %arg1110: tensor<4x64x512xbf16>, %arg1111: tensor<4x256x64xbf16>, %arg1112: tensor<4x128xbf16>, %arg1113: tensor<4x32x32x128xbf16>, %arg1114: tensor<4x64xf32>, %arg1115: tensor<4x64xf32>, %arg1116: tensor<4x64x32xbf16>, %arg1117: tensor<4x64x32xbf16>, %arg1118: tensor<4x128xf32>, %arg1119: tensor<4x128xf32>, %arg1120: tensor<4x128x128xbf16>, %arg1121: tensor<4x4x32x128xbf16>, %arg1122: tensor<4x128x128xbf16>, %arg1123: tensor<4x128x4xbf16>, %arg1124: tensor<4x4x32x128xbf16>, %arg1125: tensor<4x128x4x32xbf16>, %arg1126: tensor<4x128xf32>, %arg1127: tensor<4x128xf32>, %arg1128: tensor<4x128x128xbf16>, %arg1129: tensor<4x4x32x128xbf16>, %arg1130: tensor<4x128x128xbf16>, %arg1131: tensor<4x128x4xbf16>, %arg1132: tensor<4x4x32x128xbf16>, %arg1133: tensor<4x128x4x32xbf16>, %arg1134: tensor<4x128xf32>, %arg1135: tensor<4x128xf32>, %arg1136: tensor<4x128x1024xbf16>, %arg1137: tensor<4x512x128xbf16>, %arg1138: tensor<4x128xf32>, %arg1139: tensor<4x128xf32>, %arg1140: tensor<4x128x256xbf16>, %arg1141: tensor<4x128x128xbf16>, %arg1142: tensor<4x128xf32>, %arg1143: tensor<4x128xf32>, %arg1144: tensor<4x128x128xbf16>, %arg1145: tensor<4x128x256xbf16>, %arg1146: tensor<4x128xf32>, %arg1147: tensor<4x128xf32>, %arg1148: tensor<4x128x256xbf16>, %arg1149: tensor<4x128x128xbf16>, %arg1150: tensor<4x128xf32>, %arg1151: tensor<4x128xf32>, %arg1152: tensor<4x128x128xbf16>, %arg1153: tensor<4x128x256xbf16>, %arg1154: tensor<48x128xf32>, %arg1155: tensor<48x128xf32>, %arg1156: tensor<48x128x128xbf16>, %arg1157: tensor<48x4x32x128xbf16>, %arg1158: tensor<48x128x128xbf16>, %arg1159: tensor<48x128x4xbf16>, %arg1160: tensor<48x4x32x128xbf16>, %arg1161: tensor<48x128x4x32xbf16>, %arg1162: tensor<48x128xf32>, %arg1163: tensor<48x128xf32>, %arg1164: tensor<48x128x128xbf16>, %arg1165: tensor<48x4x32x128xbf16>, %arg1166: tensor<48x128x128xbf16>, %arg1167: tensor<48x128x4xbf16>, %arg1168: tensor<48x4x32x128xbf16>, %arg1169: tensor<48x128x4x32xbf16>, %arg1170: tensor<48x128xf32>, %arg1171: tensor<48x128xf32>, %arg1172: tensor<48x128x1024xbf16>, %arg1173: tensor<48x512x128xbf16>, %arg1174: tensor<48x384x384xbf16>, %arg1175: tensor<48x384x16x24xbf16>, %arg1176: tensor<48x384xf32>, %arg1177: tensor<48x384xf32>, %arg1178: tensor<48x16x24xbf16>, %arg1179: tensor<48x384x16x24xbf16>, %arg1180: tensor<48x384x384xbf16>, %arg1181: tensor<48x384x16x24xbf16>, %arg1182: tensor<48x128xf32>, %arg1183: tensor<48x128xf32>, %arg1184: tensor<48x128x16xbf16>, %arg1185: tensor<48x384xf32>, %arg1186: tensor<48x384xf32>, %arg1187: tensor<48x384x3072xbf16>, %arg1188: tensor<48x1536x384xbf16>, %arg1189: tensor<48x128xf32>, %arg1190: tensor<48x128xf32>, %arg1191: tensor<48x128x256xbf16>, %arg1192: tensor<48x128x128xbf16>, %arg1193: tensor<48x128xf32>, %arg1194: tensor<48x128xf32>, %arg1195: tensor<48x128x128xbf16>, %arg1196: tensor<48x128x256xbf16>, %arg1197: tensor<48x128xf32>, %arg1198: tensor<48x128xf32>, %arg1199: tensor<48x128x256xbf16>, %arg1200: tensor<48x128x128xbf16>, %arg1201: tensor<48x128xf32>, %arg1202: tensor<48x128xf32>, %arg1203: tensor<48x128x128xbf16>, %arg1204: tensor<48x128x256xbf16>, %arg1205: tensor<1x128xbf16>, %arg1206: tensor<447x64xbf16>, %arg1207: tensor<447x128xbf16>, %arg1208: tensor<34x64xbf16>, %arg1209: tensor<128x128xbf16>, %arg1210: tensor<128xf32>, %arg1211: tensor<128xf32>, %arg1212: tensor<384x384xbf16>, %arg1213: tensor<384xf32>, %arg1214: tensor<384xf32>, %arg1215: tensor<447x128xbf16>, %arg1216: tensor<447x384xbf16>, %arg1217: tensor<64x128xbf16>, %arg1218: tensor<2x64xf32>, %arg1219: tensor<2x64xf32>, %arg1220: tensor<2x64x64xbf16>, %arg1221: tensor<2x4x16x64xbf16>, %arg1222: tensor<2x64x64xbf16>, %arg1223: tensor<2x64x4xbf16>, %arg1224: tensor<2x4x16x64xbf16>, %arg1225: tensor<2x64x4x16xbf16>, %arg1226: tensor<2x64xf32>, %arg1227: tensor<2x64xf32>, %arg1228: tensor<2x64x64xbf16>, %arg1229: tensor<2x4x16x64xbf16>, %arg1230: tensor<2x64x64xbf16>, %arg1231: tensor<2x64x4xbf16>, %arg1232: tensor<2x4x16x64xbf16>, %arg1233: tensor<2x64x4x16xbf16>, %arg1234: tensor<2x64xf32>, %arg1235: tensor<2x64xf32>, %arg1236: tensor<2x64x256xbf16>, %arg1237: tensor<2x128x64xbf16>, %arg1238: tensor<2x64xf32>, %arg1239: tensor<2x64xf32>, %arg1240: tensor<2x64x128xbf16>, %arg1241: tensor<2x64x64xbf16>, %arg1242: tensor<2x64xf32>, %arg1243: tensor<2x64xf32>, %arg1244: tensor<2x64x64xbf16>, %arg1245: tensor<2x64x128xbf16>, %arg1246: tensor<2x64xf32>, %arg1247: tensor<2x64xf32>, %arg1248: tensor<2x64x128xbf16>, %arg1249: tensor<2x64x64xbf16>, %arg1250: tensor<2x64xf32>, %arg1251: tensor<2x64xf32>, %arg1252: tensor<2x64x64xbf16>, %arg1253: tensor<2x64x128xbf16>, %arg1254: tensor<64xf32>, %arg1255: tensor<64xf32>, %arg1256: tensor<128xf32>, %arg1257: tensor<128xf32>, %arg1258: tensor<39x64xbf16>, %arg1259: tensor<64xbf16>, %arg1260: tensor<31x64xbf16>, %arg1261: tensor<31x64xbf16>, %arg1262: tensor<64xbf16>, %arg1263: tensor<64xbf16>, %arg1264: tensor<64xbf16>, %arg1265: tensor<64xbf16>, %arg1266: tensor<128x64xbf16>, %arg1267: tensor<139x128xbf16>, %arg1268: tensor<2xui32>, %arg1269: tensor<2xui32>, %arg1270: tensor<768x768x128xf32>, %arg1271: tensor<768x384xf32>, %arg1272: tensor<768x447xbf16>, %arg1273: tensor<2xui32>, %arg1274: tensor<768x447xbf16>, %arg1275: tensor<768xi1>, %arg1276: tensor<768xi32>, %arg1277: tensor<768xi32>, %arg1278: tensor<768xi32>, %arg1279: tensor<768xi32>, %arg1280: tensor<768xi32>, %arg1281: tensor<768x2xi1>, %arg1282: tensor<768x2xi32>, %arg1283: tensor<7680x2xi1>, %arg1284: tensor<7680x2xi32>, %arg1285: tensor<4x768xi32>, %arg1286: tensor<4x768x24xi1>, %arg1287: tensor<4x768x24x3xf32>, %arg1288: tensor<16384x768xi1>, %arg1289: tensor<16384x768xi8>, %arg1290: tensor<16384x768xi8>):
  %388 = "mhlo.constant"() <{value = dense<11> : tensor<i32>}> : () -> tensor<i32>
  %389 = "mhlo.compare"(%arg1099, %388) <{compare_type = #mhlo<comparison_type SIGNED>, comparison_direction = #mhlo<comparison_direction LT>}> : (tensor<i32>, tensor<i32>) -> tensor<i1>
  "mhlo.return"(%389) : (tensor<i1>) -> ()
}, {
^bb0(%arg907: tensor<i32>, %arg908: tensor<4x64xf32>, %arg909: tensor<4x64xf32>, %arg910: tensor<4x64x64xbf16>, %arg911: tensor<4x64x64xbf16>, %arg912: tensor<4x128x8xbf16>, %arg913: tensor<4x128xf32>, %arg914: tensor<4x128xf32>, %arg915: tensor<4x64x8x8xbf16>, %arg916: tensor<4x64xf32>, %arg917: tensor<4x64xf32>, %arg918: tensor<4x64x512xbf16>, %arg919: tensor<4x256x64xbf16>, %arg920: tensor<4x128xbf16>, %arg921: tensor<4x32x32x128xbf16>, %arg922: tensor<4x64xf32>, %arg923: tensor<4x64xf32>, %arg924: tensor<4x64x32xbf16>, %arg925: tensor<4x64x32xbf16>, %arg926: tensor<4x128xf32>, %arg927: tensor<4x128xf32>, %arg928: tensor<4x128x128xbf16>, %arg929: tensor<4x4x32x128xbf16>, %arg930: tensor<4x128x128xbf16>, %arg931: tensor<4x128x4xbf16>, %arg932: tensor<4x4x32x128xbf16>, %arg933: tensor<4x128x4x32xbf16>, %arg934: tensor<4x128xf32>, %arg935: tensor<4x128xf32>, %arg936: tensor<4x128x128xbf16>, %arg937: tensor<4x4x32x128xbf16>, %arg938: tensor<4x128x128xbf16>, %arg939: tensor<4x128x4xbf16>, %arg940: tensor<4x4x32x128xbf16>, %arg941: tensor<4x128x4x32xbf16>, %arg942: tensor<4x128xf32>, %arg943: tensor<4x128xf32>, %arg944: tensor<4x128x1024xbf16>, %arg945: tensor<4x512x128xbf16>, %arg946: tensor<4x128xf32>, %arg947: tensor<4x128xf32>, %arg948: tensor<4x128x256xbf16>, %arg949: tensor<4x128x128xbf16>, %arg950: tensor<4x128xf32>, %arg951: tensor<4x128xf32>, %arg952: tensor<4x128x128xbf16>, %arg953: tensor<4x128x256xbf16>, %arg954: tensor<4x128xf32>, %arg955: tensor<4x128xf32>, %arg956: tensor<4x128x256xbf16>, %arg957: tensor<4x128x128xbf16>, %arg958: tensor<4x128xf32>, %arg959: tensor<4x128xf32>, %arg960: tensor<4x128x128xbf16>, %arg961: tensor<4x128x256xbf16>, %arg962: tensor<48x128xf32>, %arg963: tensor<48x128xf32>, %arg964: tensor<48x128x128xbf16>, %arg965: tensor<48x4x32x128xbf16>, %arg966: tensor<48x128x128xbf16>, %arg967: tensor<48x128x4xbf16>, %arg968: tensor<48x4x32x128xbf16>, %arg969: tensor<48x128x4x32xbf16>, %arg970: tensor<48x128xf32>, %arg971: tensor<48x128xf32>, %arg972: tensor<48x128x128xbf16>, %arg973: tensor<48x4x32x128xbf16>, %arg974: tensor<48x128x128xbf16>, %arg975: tensor<48x128x4xbf16>, %arg976: tensor<48x4x32x128xbf16>, %arg977: tensor<48x128x4x32xbf16>, %arg978: tensor<48x128xf32>, %arg979: tensor<48x128xf32>, %arg980: tensor<48x128x1024xbf16>, %arg981: tensor<48x512x128xbf16>, %arg982: tensor<48x384x384xbf16>, %arg983: tensor<48x384x16x24xbf16>, %arg984: tensor<48x384xf32>, %arg985: tensor<48x384xf32>, %arg986: tensor<48x16x24xbf16>, %arg987: tensor<48x384x16x24xbf16>, %arg988: tensor<48x384x384xbf16>, %arg989: tensor<48x384x16x24xbf16>, %arg990: tensor<48x128xf32>, %arg991: tensor<48x128xf32>, %arg992: tensor<48x128x16xbf16>, %arg993: tensor<48x384xf32>, %arg994: tensor<48x384xf32>, %arg995: tensor<48x384x3072xbf16>, %arg996: tensor<48x1536x384xbf16>, %arg997: tensor<48x128xf32>, %arg998: tensor<48x128xf32>, %arg999: tensor<48x128x256xbf16>, %arg1000: tensor<48x128x128xbf16>, %arg1001: tensor<48x128xf32>, %arg1002: tensor<48x128xf32>, %arg1003: tensor<48x128x128xbf16>, %arg1004: tensor<48x128x256xbf16>, %arg1005: tensor<48x128xf32>, %arg1006: tensor<48x128xf32>, %arg1007: tensor<48x128x256xbf16>, %arg1008: tensor<48x128x128xbf16>, %arg1009: tensor<48x128xf32>, %arg1010: tensor<48x128xf32>, %arg1011: tensor<48x128x128xbf16>, %arg1012: tensor<48x128x256xbf16>, %arg1013: tensor<1x128xbf16>, %arg1014: tensor<447x64xbf16>, %arg1015: tensor<447x128xbf16>, %arg1016: tensor<34x64xbf16>, %arg1017: tensor<128x128xbf16>, %arg1018: tensor<128xf32>, %arg1019: tensor<128xf32>, %arg1020: tensor<384x384xbf16>, %arg1021: tensor<384xf32>, %arg1022: tensor<384xf32>, %arg1023: tensor<447x128xbf16>, %arg1024: tensor<447x384xbf16>, %arg1025: tensor<64x128xbf16>, %arg1026: tensor<2x64xf32>, %arg1027: tensor<2x64xf32>, %arg1028: tensor<2x64x64xbf16>, %arg1029: tensor<2x4x16x64xbf16>, %arg1030: tensor<2x64x64xbf16>, %arg1031: tensor<2x64x4xbf16>, %arg1032: tensor<2x4x16x64xbf16>, %arg1033: tensor<2x64x4x16xbf16>, %arg1034: tensor<2x64xf32>, %arg1035: tensor<2x64xf32>, %arg1036: tensor<2x64x64xbf16>, %arg1037: tensor<2x4x16x64xbf16>, %arg1038: tensor<2x64x64xbf16>, %arg1039: tensor<2x64x4xbf16>, %arg1040: tensor<2x4x16x64xbf16>, %arg1041: tensor<2x64x4x16xbf16>, %arg1042: tensor<2x64xf32>, %arg1043: tensor<2x64xf32>, %arg1044: tensor<2x64x256xbf16>, %arg1045: tensor<2x128x64xbf16>, %arg1046: tensor<2x64xf32>, %arg1047: tensor<2x64xf32>, %arg1048: tensor<2x64x128xbf16>, %arg1049: tensor<2x64x64xbf16>, %arg1050: tensor<2x64xf32>, %arg1051: tensor<2x64xf32>, %arg1052: tensor<2x64x64xbf16>, %arg1053: tensor<2x64x128xbf16>, %arg1054: tensor<2x64xf32>, %arg1055: tensor<2x64xf32>, %arg1056: tensor<2x64x128xbf16>, %arg1057: tensor<2x64x64xbf16>, %arg1058: tensor<2x64xf32>, %arg1059: tensor<2x64xf32>, %arg1060: tensor<2x64x64xbf16>, %arg1061: tensor<2x64x128xbf16>, %arg1062: tensor<64xf32>, %arg1063: tensor<64xf32>, %arg1064: tensor<128xf32>, %arg1065: tensor<128xf32>, %arg1066: tensor<39x64xbf16>, %arg1067: tensor<64xbf16>, %arg1068: tensor<31x64xbf16>, %arg1069: tensor<31x64xbf16>, %arg1070: tensor<64xbf16>, %arg1071: tensor<64xbf16>, %arg1072: tensor<64xbf16>, %arg1073: tensor<64xbf16>, %arg1074: tensor<128x64xbf16>, %arg1075: tensor<139x128xbf16>, %arg1076: tensor<2xui32>, %arg1077: tensor<2xui32>, %arg1078: tensor<768x768x128xf32>, %arg1079: tensor<768x384xf32>, %arg1080: tensor<768x447xbf16>, %arg1081: tensor<2xui32>, %arg1082: tensor<768x447xbf16>, %arg1083: tensor<768xi1>, %arg1084: tensor<768xi32>, %arg1085: tensor<768xi32>, %arg1086: tensor<768xi32>, %arg1087: tensor<768xi32>, %arg1088: tensor<768xi32>, %arg1089: tensor<768x2xi1>, %arg1090: tensor<768x2xi32>, %arg1091: tensor<7680x2xi1>, %arg1092: tensor<7680x2xi32>, %arg1093: tensor<4x768xi32>, %arg1094: tensor<4x768x24xi1>, %arg1095: tensor<4x768x24x3xf32>, %arg1096: tensor<16384x768xi1>, %arg1097: tensor<16384x768xi8>, %arg1098: tensor<16384x768xi8>):
  %381 = "mhlo.constant"() <{value = dense<1> : tensor<i32>}> : () -> tensor<i32>
  %382 = "mhlo.constant"() <{value = dense<[0, 128, 256, 384, 512, 640]> : tensor<6xi32>}> : () -> tensor<6xi32>
  %383 = "mhlo.constant"() <{value = dense_resource<__elided__> : tensor<31x8x3xi32>}> : () -> tensor<31x8x3xi32>
  %384 = "mhlo.constant"() <{value = dense<1.000000e+08> : tensor<1xf32>}> : () -> tensor<1xf32>
  %385 = "mhlo.constant"() <{value = dense_resource<__elided__> : tensor<31xi32>}> : () -> tensor<31xi32>
  %386:174 = "func.call"(%arg1082, %arg1083, %arg1084, %arg1085, %arg1086, %arg1087, %arg1088, %arg1089, %arg1090, %arg1091, %arg1092, %385, %384, %383, %382, %382, %arg1093, %arg1094, %arg1095, %arg1096, %arg1097, %arg1098, %382, %382, %382, %382, %382, %arg908, %arg909, %arg910, %arg911, %arg912, %arg913, %arg914, %arg915, %arg916, %arg917, %arg918, %arg919, %arg920, %arg921, %arg922, %arg923, %arg924, %arg925, %arg926, %arg927, %arg928, %arg929, %arg930, %arg931, %arg932, %arg933, %arg934, %arg935, %arg936, %arg937, %arg938, %arg939, %arg940, %arg941, %arg942, %arg943, %arg944, %arg945, %arg946, %arg947, %arg948, %arg949, %arg950, %arg951, %arg952, %arg953, %arg954, %arg955, %arg956, %arg957, %arg958, %arg959, %arg960, %arg961, %arg962, %arg963, %arg964, %arg965, %arg966, %arg967, %arg968, %arg969, %arg970, %arg971, %arg972, %arg973, %arg974, %arg975, %arg976, %arg977, %arg978, %arg979, %arg980, %arg981, %arg982, %arg983, %arg984, %arg985, %arg986, %arg987, %arg988, %arg989, %arg990, %arg991, %arg992, %arg993, %arg994, %arg995, %arg996, %arg997, %arg998, %arg999, %arg1000, %arg1001, %arg1002, %arg1003, %arg1004, %arg1005, %arg1006, %arg1007, %arg1008, %arg1009, %arg1010, %arg1011, %arg1012, %arg1013, %arg1014, %arg1015, %arg1016, %arg1017, %arg1018, %arg1019, %arg1020, %arg1021, %arg1022, %arg1023, %arg1024, %arg1025, %arg1026, %arg1027, %arg1028, %arg1029, %arg1030, %arg1031, %arg1032, %arg1033, %arg1034, %arg1035, %arg1036, %arg1037, %arg1038, %arg1039, %arg1040, %arg1041, %arg1042, %arg1043, %arg1044, %arg1045, %arg1046, %arg1047, %arg1048, %arg1049, %arg1050, %arg1051, %arg1052, %arg1053, %arg1054, %arg1055, %arg1056, %arg1057, %arg1058, %arg1059, %arg1060, %arg1061, %arg1062, %arg1063, %arg1064, %arg1065, %arg1066, %arg1067, %arg1068, %arg1069, %arg1070, %arg1071, %arg1072, %arg1073, %arg1074, %arg1075, %arg1076, %arg1077, %arg1078, %arg1079, %arg1080, %arg1081) <{callee = @None_9}> : (tensor<768x447xbf16>, tensor<768xi1>, tensor<768xi32>, tensor<768xi32>, tensor<768xi32>, tensor<768xi32>, tensor<768xi32>, tensor<768x2xi1>, tensor<768x2xi32>, tensor<7680x2xi1>, tensor<7680x2xi32>, tensor<31xi32>, tensor<1xf32>, tensor<31x8x3xi32>, tensor<6xi32>, tensor<6xi32>, tensor<4x768xi32>, tensor<4x768x24xi1>, tensor<4x768x24x3xf32>, tensor<16384x768xi1>, tensor<16384x768xi8>, tensor<16384x768xi8>, tensor<6xi32>, tensor<6xi32>, tensor<6xi32>, tensor<6xi32>, tensor<6xi32>, tensor<4x64xf32>, tensor<4x64xf32>, tensor<4x64x64xbf16>, tensor<4x64x64xbf16>, tensor<4x128x8xbf16>, tensor<4x128xf32>, tensor<4x128xf32>, tensor<4x64x8x8xbf16>, tensor<4x64xf32>, tensor<4x64xf32>, tensor<4x64x512xbf16>, tensor<4x256x64xbf16>, tensor<4x128xbf16>, tensor<4x32x32x128xbf16>, tensor<4x64xf32>, tensor<4x64xf32>, tensor<4x64x32xbf16>, tensor<4x64x32xbf16>, tensor<4x128xf32>, tensor<4x128xf32>, tensor<4x128x128xbf16>, tensor<4x4x32x128xbf16>, tensor<4x128x128xbf16>, tensor<4x128x4xbf16>, tensor<4x4x32x128xbf16>, tensor<4x128x4x32xbf16>, tensor<4x128xf32>, tensor<4x128xf32>, tensor<4x128x128xbf16>, tensor<4x4x32x128xbf16>, tensor<4x128x128xbf16>, tensor<4x128x4xbf16>, tensor<4x4x32x128xbf16>, tensor<4x128x4x32xbf16>, tensor<4x128xf32>, tensor<4x128xf32>, tensor<4x128x1024xbf16>, tensor<4x512x128xbf16>, tensor<4x128xf32>, tensor<4x128xf32>, tensor<4x128x256xbf16>, tensor<4x128x128xbf16>, tensor<4x128xf32>, tensor<4x128xf32>, tensor<4x128x128xbf16>, tensor<4x128x256xbf16>, tensor<4x128xf32>, tensor<4x128xf32>, tensor<4x128x256xbf16>, tensor<4x128x128xbf16>, tensor<4x128xf32>, tensor<4x128xf32>, tensor<4x128x128xbf16>, tensor<4x128x256xbf16>, tensor<48x128xf32>, tensor<48x128xf32>, tensor<48x128x128xbf16>, tensor<48x4x32x128xbf16>, tensor<48x128x128xbf16>, tensor<48x128x4xbf16>, tensor<48x4x32x128xbf16>, tensor<48x128x4x32xbf16>, tensor<48x128xf32>, tensor<48x128xf32>, tensor<48x128x128xbf16>, tensor<48x4x32x128xbf16>, tensor<48x128x128xbf16>, tensor<48x128x4xbf16>, tensor<48x4x32x128xbf16>, tensor<48x128x4x32xbf16>, tensor<48x128xf32>, tensor<48x128xf32>, tensor<48x128x1024xbf16>, tensor<48x512x128xbf16>, tensor<48x384x384xbf16>, tensor<48x384x16x24xbf16>, tensor<48x384xf32>, tensor<48x384xf32>, tensor<48x16x24xbf16>, tensor<48x384x16x24xbf16>, tensor<48x384x384xbf16>, tensor<48x384x16x24xbf16>, tensor<48x128xf32>, tensor<48x128xf32>, tensor<48x128x16xbf16>, tensor<48x384xf32>, tensor<48x384xf32>, tensor<48x384x3072xbf16>, tensor<48x1536x384xbf16>, tensor<48x128xf32>, tensor<48x128xf32>, tensor<48x128x256xbf16>, tensor<48x128x128xbf16>, tensor<48x128xf32>, tensor<48x128xf32>, tensor<48x128x128xbf16>, tensor<48x128x256xbf16>, tensor<48x128xf32>, tensor<48x128xf32>, tensor<48x128x256xbf16>, tensor<48x128x128xbf16>, tensor<48x128xf32>, tensor<48x128xf32>, tensor<48x128x128xbf16>, tensor<48x128x256xbf16>, tensor<1x128xbf16>, tensor<447x64xbf16>, tensor<447x128xbf16>, tensor<34x64xbf16>, tensor<128x128xbf16>, tensor<128xf32>, tensor<128xf32>, tensor<384x384xbf16>, tensor<384xf32>, tensor<384xf32>, tensor<447x128xbf16>, tensor<447x384xbf16>, tensor<64x128xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x64xbf16>, tensor<2x4x16x64xbf16>, tensor<2x64x64xbf16>, tensor<2x64x4xbf16>, tensor<2x4x16x64xbf16>, tensor<2x64x4x16xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x64xbf16>, tensor<2x4x16x64xbf16>, tensor<2x64x64xbf16>, tensor<2x64x4xbf16>, tensor<2x4x16x64xbf16>, tensor<2x64x4x16xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x256xbf16>, tensor<2x128x64xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x128xbf16>, tensor<2x64x64xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x64xbf16>, tensor<2x64x128xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x128xbf16>, tensor<2x64x64xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x64xbf16>, tensor<2x64x128xbf16>, tensor<64xf32>, tensor<64xf32>, tensor<128xf32>, tensor<128xf32>, tensor<39x64xbf16>, tensor<64xbf16>, tensor<31x64xbf16>, tensor<31x64xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<128x64xbf16>, tensor<139x128xbf16>, tensor<2xui32>, tensor<2xui32>, tensor<768x768x128xf32>, tensor<768x384xf32>, tensor<768x447xbf16>, tensor<2xui32>) -> (tensor<4x64xf32>, tensor<4x64xf32>, tensor<4x64x64xbf16>, tensor<4x64x64xbf16>, tensor<4x128x8xbf16>, tensor<4x128xf32>, tensor<4x128xf32>, tensor<4x64x8x8xbf16>, tensor<4x64xf32>, tensor<4x64xf32>, tensor<4x64x512xbf16>, tensor<4x256x64xbf16>, tensor<4x128xbf16>, tensor<4x32x32x128xbf16>, tensor<4x64xf32>, tensor<4x64xf32>, tensor<4x64x32xbf16>, tensor<4x64x32xbf16>, tensor<4x128xf32>, tensor<4x128xf32>, tensor<4x128x128xbf16>, tensor<4x4x32x128xbf16>, tensor<4x128x128xbf16>, tensor<4x128x4xbf16>, tensor<4x4x32x128xbf16>, tensor<4x128x4x32xbf16>, tensor<4x128xf32>, tensor<4x128xf32>, tensor<4x128x128xbf16>, tensor<4x4x32x128xbf16>, tensor<4x128x128xbf16>, tensor<4x128x4xbf16>, tensor<4x4x32x128xbf16>, tensor<4x128x4x32xbf16>, tensor<4x128xf32>, tensor<4x128xf32>, tensor<4x128x1024xbf16>, tensor<4x512x128xbf16>, tensor<4x128xf32>, tensor<4x128xf32>, tensor<4x128x256xbf16>, tensor<4x128x128xbf16>, tensor<4x128xf32>, tensor<4x128xf32>, tensor<4x128x128xbf16>, tensor<4x128x256xbf16>, tensor<4x128xf32>, tensor<4x128xf32>, tensor<4x128x256xbf16>, tensor<4x128x128xbf16>, tensor<4x128xf32>, tensor<4x128xf32>, tensor<4x128x128xbf16>, tensor<4x128x256xbf16>, tensor<48x128xf32>, tensor<48x128xf32>, tensor<48x128x128xbf16>, tensor<48x4x32x128xbf16>, tensor<48x128x128xbf16>, tensor<48x128x4xbf16>, tensor<48x4x32x128xbf16>, tensor<48x128x4x32xbf16>, tensor<48x128xf32>, tensor<48x128xf32>, tensor<48x128x128xbf16>, tensor<48x4x32x128xbf16>, tensor<48x128x128xbf16>, tensor<48x128x4xbf16>, tensor<48x4x32x128xbf16>, tensor<48x128x4x32xbf16>, tensor<48x128xf32>, tensor<48x128xf32>, tensor<48x128x1024xbf16>, tensor<48x512x128xbf16>, tensor<48x384x384xbf16>, tensor<48x384x16x24xbf16>, tensor<48x384xf32>, tensor<48x384xf32>, tensor<48x16x24xbf16>, tensor<48x384x16x24xbf16>, tensor<48x384x384xbf16>, tensor<48x384x16x24xbf16>, tensor<48x128xf32>, tensor<48x128xf32>, tensor<48x128x16xbf16>, tensor<48x384xf32>, tensor<48x384xf32>, tensor<48x384x3072xbf16>, tensor<48x1536x384xbf16>, tensor<48x128xf32>, tensor<48x128xf32>, tensor<48x128x256xbf16>, tensor<48x128x128xbf16>, tensor<48x128xf32>, tensor<48x128xf32>, tensor<48x128x128xbf16>, tensor<48x128x256xbf16>, tensor<48x128xf32>, tensor<48x128xf32>, tensor<48x128x256xbf16>, tensor<48x128x128xbf16>, tensor<48x128xf32>, tensor<48x128xf32>, tensor<48x128x128xbf16>, tensor<48x128x256xbf16>, tensor<1x128xbf16>, tensor<447x64xbf16>, tensor<447x128xbf16>, tensor<34x64xbf16>, tensor<128x128xbf16>, tensor<128xf32>, tensor<128xf32>, tensor<384x384xbf16>, tensor<384xf32>, tensor<384xf32>, tensor<447x128xbf16>, tensor<447x384xbf16>, tensor<64x128xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x64xbf16>, tensor<2x4x16x64xbf16>, tensor<2x64x64xbf16>, tensor<2x64x4xbf16>, tensor<2x4x16x64xbf16>, tensor<2x64x4x16xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x64xbf16>, tensor<2x4x16x64xbf16>, tensor<2x64x64xbf16>, tensor<2x64x4xbf16>, tensor<2x4x16x64xbf16>, tensor<2x64x4x16xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x256xbf16>, tensor<2x128x64xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x128xbf16>, tensor<2x64x64xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x64xbf16>, tensor<2x64x128xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x128xbf16>, tensor<2x64x64xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x64xbf16>, tensor<2x64x128xbf16>, tensor<64xf32>, tensor<64xf32>, tensor<128xf32>, tensor<128xf32>, tensor<39x64xbf16>, tensor<64xbf16>, tensor<31x64xbf16>, tensor<31x64xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<128x64xbf16>, tensor<139x128xbf16>, tensor<2xui32>, tensor<2xui32>, tensor<768x768x128xf32>, tensor<768x384xf32>, tensor<768x447xbf16>, tensor<2xui32>)
  %387 = "mhlo.add"(%arg907, %381) : (tensor<i32>, tensor<i32>) -> tensor<i32>
  "mhlo.return"(%387, %386#0, %386#1, %386#2, %386#3, %386#4, %386#5, %386#6, %386#7, %386#8, %386#9, %386#10, %386#11, %386#12, %386#13, %386#14, %386#15, %386#16, %386#17, %386#18, %386#19, %386#20, %386#21, %386#22, %386#23, %386#24, %386#25, %386#26, %386#27, %386#28, %386#29, %386#30, %386#31, %386#32, %386#33, %386#34, %386#35, %386#36, %386#37, %386#38, %386#39, %386#40, %386#41, %386#42, %386#43, %386#44, %386#45, %386#46, %386#47, %386#48, %386#49, %386#50, %386#51, %386#52, %386#53, %386#54, %386#55, %386#56, %386#57, %386#58, %386#59, %386#60, %386#61, %386#62, %386#63, %386#64, %386#65, %386#66, %386#67, %386#68, %386#69, %386#70, %386#71, %386#72, %386#73, %386#74, %386#75, %386#76, %386#77, %386#78, %386#79, %386#80, %386#81, %386#82, %386#83, %386#84, %386#85, %386#86, %386#87, %386#88, %386#89, %386#90, %386#91, %386#92, %386#93, %386#94, %386#95, %386#96, %386#97, %386#98, %386#99, %386#100, %386#101, %386#102, %386#103, %386#104, %386#105, %386#106, %386#107, %386#108, %386#109, %386#110, %386#111, %386#112, %386#113, %386#114, %386#115, %386#116, %386#117, %386#118, %386#119, %386#120, %386#121, %386#122, %386#123, %386#124, %386#125, %386#126, %386#127, %386#128, %386#129, %386#130, %386#131, %386#132, %386#133, %386#134, %386#135, %386#136, %386#137, %386#138, %386#139, %386#140, %386#141, %386#142, %386#143, %386#144, %386#145, %386#146, %386#147, %386#148, %386#149, %386#150, %386#151, %386#152, %386#153, %386#154, %386#155, %386#156, %386#157, %386#158, %386#159, %386#160, %386#161, %386#162, %386#163, %386#164, %386#165, %386#166, %386#167, %386#168, %386#169, %386#170, %386#171, %386#172, %386#173, %arg1082, %arg1083, %arg1084, %arg1085, %arg1086, %arg1087, %arg1088, %arg1089, %arg1090, %arg1091, %arg1092, %arg1093, %arg1094, %arg1095, %arg1096, %arg1097, %arg1098) : (tensor<i32>, tensor<4x64xf32>, tensor<4x64xf32>, tensor<4x64x64xbf16>, tensor<4x64x64xbf16>, tensor<4x128x8xbf16>, tensor<4x128xf32>, tensor<4x128xf32>, tensor<4x64x8x8xbf16>, tensor<4x64xf32>, tensor<4x64xf32>, tensor<4x64x512xbf16>, tensor<4x256x64xbf16>, tensor<4x128xbf16>, tensor<4x32x32x128xbf16>, tensor<4x64xf32>, tensor<4x64xf32>, tensor<4x64x32xbf16>, tensor<4x64x32xbf16>, tensor<4x128xf32>, tensor<4x128xf32>, tensor<4x128x128xbf16>, tensor<4x4x32x128xbf16>, tensor<4x128x128xbf16>, tensor<4x128x4xbf16>, tensor<4x4x32x128xbf16>, tensor<4x128x4x32xbf16>, tensor<4x128xf32>, tensor<4x128xf32>, tensor<4x128x128xbf16>, tensor<4x4x32x128xbf16>, tensor<4x128x128xbf16>, tensor<4x128x4xbf16>, tensor<4x4x32x128xbf16>, tensor<4x128x4x32xbf16>, tensor<4x128xf32>, tensor<4x128xf32>, tensor<4x128x1024xbf16>, tensor<4x512x128xbf16>, tensor<4x128xf32>, tensor<4x128xf32>, tensor<4x128x256xbf16>, tensor<4x128x128xbf16>, tensor<4x128xf32>, tensor<4x128xf32>, tensor<4x128x128xbf16>, tensor<4x128x256xbf16>, tensor<4x128xf32>, tensor<4x128xf32>, tensor<4x128x256xbf16>, tensor<4x128x128xbf16>, tensor<4x128xf32>, tensor<4x128xf32>, tensor<4x128x128xbf16>, tensor<4x128x256xbf16>, tensor<48x128xf32>, tensor<48x128xf32>, tensor<48x128x128xbf16>, tensor<48x4x32x128xbf16>, tensor<48x128x128xbf16>, tensor<48x128x4xbf16>, tensor<48x4x32x128xbf16>, tensor<48x128x4x32xbf16>, tensor<48x128xf32>, tensor<48x128xf32>, tensor<48x128x128xbf16>, tensor<48x4x32x128xbf16>, tensor<48x128x128xbf16>, tensor<48x128x4xbf16>, tensor<48x4x32x128xbf16>, tensor<48x128x4x32xbf16>, tensor<48x128xf32>, tensor<48x128xf32>, tensor<48x128x1024xbf16>, tensor<48x512x128xbf16>, tensor<48x384x384xbf16>, tensor<48x384x16x24xbf16>, tensor<48x384xf32>, tensor<48x384xf32>, tensor<48x16x24xbf16>, tensor<48x384x16x24xbf16>, tensor<48x384x384xbf16>, tensor<48x384x16x24xbf16>, tensor<48x128xf32>, tensor<48x128xf32>, tensor<48x128x16xbf16>, tensor<48x384xf32>, tensor<48x384xf32>, tensor<48x384x3072xbf16>, tensor<48x1536x384xbf16>, tensor<48x128xf32>, tensor<48x128xf32>, tensor<48x128x256xbf16>, tensor<48x128x128xbf16>, tensor<48x128xf32>, tensor<48x128xf32>, tensor<48x128x128xbf16>, tensor<48x128x256xbf16>, tensor<48x128xf32>, tensor<48x128xf32>, tensor<48x128x256xbf16>, tensor<48x128x128xbf16>, tensor<48x128xf32>, tensor<48x128xf32>, tensor<48x128x128xbf16>, tensor<48x128x256xbf16>, tensor<1x128xbf16>, tensor<447x64xbf16>, tensor<447x128xbf16>, tensor<34x64xbf16>, tensor<128x128xbf16>, tensor<128xf32>, tensor<128xf32>, tensor<384x384xbf16>, tensor<384xf32>, tensor<384xf32>, tensor<447x128xbf16>, tensor<447x384xbf16>, tensor<64x128xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x64xbf16>, tensor<2x4x16x64xbf16>, tensor<2x64x64xbf16>, tensor<2x64x4xbf16>, tensor<2x4x16x64xbf16>, tensor<2x64x4x16xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x64xbf16>, tensor<2x4x16x64xbf16>, tensor<2x64x64xbf16>, tensor<2x64x4xbf16>, tensor<2x4x16x64xbf16>, tensor<2x64x4x16xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x256xbf16>, tensor<2x128x64xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x128xbf16>, tensor<2x64x64xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x64xbf16>, tensor<2x64x128xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x128xbf16>, tensor<2x64x64xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x64xbf16>, tensor<2x64x128xbf16>, tensor<64xf32>, tensor<64xf32>, tensor<128xf32>, tensor<128xf32>, tensor<39x64xbf16>, tensor<64xbf16>, tensor<31x64xbf16>, tensor<31x64xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<128x64xbf16>, tensor<139x128xbf16>, tensor<2xui32>, tensor<2xui32>, tensor<768x768x128xf32>, tensor<768x384xf32>, tensor<768x447xbf16>, tensor<2xui32>, tensor<768x447xbf16>, tensor<768xi1>, tensor<768xi32>, tensor<768xi32>, tensor<768xi32>, tensor<768xi32>, tensor<768xi32>, tensor<768x2xi1>, tensor<768x2xi32>, tensor<7680x2xi1>, tensor<7680x2xi32>, tensor<4x768xi32>, tensor<4x768x24xi1>, tensor<4x768x24x3xf32>, tensor<16384x768xi1>, tensor<16384x768xi8>, tensor<16384x768xi8>) -> ()
}) : (tensor<i32>, tensor<4x64xf32>, tensor<4x64xf32>, tensor<4x64x64xbf16>, tensor<4x64x64xbf16>, tensor<4x128x8xbf16>, tensor<4x128xf32>, tensor<4x128xf32>, tensor<4x64x8x8xbf16>, tensor<4x64xf32>, tensor<4x64xf32>, tensor<4x64x512xbf16>, tensor<4x256x64xbf16>, tensor<4x128xbf16>, tensor<4x32x32x128xbf16>, tensor<4x64xf32>, tensor<4x64xf32>, tensor<4x64x32xbf16>, tensor<4x64x32xbf16>, tensor<4x128xf32>, tensor<4x128xf32>, tensor<4x128x128xbf16>, tensor<4x4x32x128xbf16>, tensor<4x128x128xbf16>, tensor<4x128x4xbf16>, tensor<4x4x32x128xbf16>, tensor<4x128x4x32xbf16>, tensor<4x128xf32>, tensor<4x128xf32>, tensor<4x128x128xbf16>, tensor<4x4x32x128xbf16>, tensor<4x128x128xbf16>, tensor<4x128x4xbf16>, tensor<4x4x32x128xbf16>, tensor<4x128x4x32xbf16>, tensor<4x128xf32>, tensor<4x128xf32>, tensor<4x128x1024xbf16>, tensor<4x512x128xbf16>, tensor<4x128xf32>, tensor<4x128xf32>, tensor<4x128x256xbf16>, tensor<4x128x128xbf16>, tensor<4x128xf32>, tensor<4x128xf32>, tensor<4x128x128xbf16>, tensor<4x128x256xbf16>, tensor<4x128xf32>, tensor<4x128xf32>, tensor<4x128x256xbf16>, tensor<4x128x128xbf16>, tensor<4x128xf32>, tensor<4x128xf32>, tensor<4x128x128xbf16>, tensor<4x128x256xbf16>, tensor<48x128xf32>, tensor<48x128xf32>, tensor<48x128x128xbf16>, tensor<48x4x32x128xbf16>, tensor<48x128x128xbf16>, tensor<48x128x4xbf16>, tensor<48x4x32x128xbf16>, tensor<48x128x4x32xbf16>, tensor<48x128xf32>, tensor<48x128xf32>, tensor<48x128x128xbf16>, tensor<48x4x32x128xbf16>, tensor<48x128x128xbf16>, tensor<48x128x4xbf16>, tensor<48x4x32x128xbf16>, tensor<48x128x4x32xbf16>, tensor<48x128xf32>, tensor<48x128xf32>, tensor<48x128x1024xbf16>, tensor<48x512x128xbf16>, tensor<48x384x384xbf16>, tensor<48x384x16x24xbf16>, tensor<48x384xf32>, tensor<48x384xf32>, tensor<48x16x24xbf16>, tensor<48x384x16x24xbf16>, tensor<48x384x384xbf16>, tensor<48x384x16x24xbf16>, tensor<48x128xf32>, tensor<48x128xf32>, tensor<48x128x16xbf16>, tensor<48x384xf32>, tensor<48x384xf32>, tensor<48x384x3072xbf16>, tensor<48x1536x384xbf16>, tensor<48x128xf32>, tensor<48x128xf32>, tensor<48x128x256xbf16>, tensor<48x128x128xbf16>, tensor<48x128xf32>, tensor<48x128xf32>, tensor<48x128x128xbf16>, tensor<48x128x256xbf16>, tensor<48x128xf32>, tensor<48x128xf32>, tensor<48x128x256xbf16>, tensor<48x128x128xbf16>, tensor<48x128xf32>, tensor<48x128xf32>, tensor<48x128x128xbf16>, tensor<48x128x256xbf16>, tensor<1x128xbf16>, tensor<447x64xbf16>, tensor<447x128xbf16>, tensor<34x64xbf16>, tensor<128x128xbf16>, tensor<128xf32>, tensor<128xf32>, tensor<384x384xbf16>, tensor<384xf32>, tensor<384xf32>, tensor<447x128xbf16>, tensor<447x384xbf16>, tensor<64x128xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x64xbf16>, tensor<2x4x16x64xbf16>, tensor<2x64x64xbf16>, tensor<2x64x4xbf16>, tensor<2x4x16x64xbf16>, tensor<2x64x4x16xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x64xbf16>, tensor<2x4x16x64xbf16>, tensor<2x64x64xbf16>, tensor<2x64x4xbf16>, tensor<2x4x16x64xbf16>, tensor<2x64x4x16xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x256xbf16>, tensor<2x128x64xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x128xbf16>, tensor<2x64x64xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x64xbf16>, tensor<2x64x128xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x128xbf16>, tensor<2x64x64xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x64xbf16>, tensor<2x64x128xbf16>, tensor<64xf32>, tensor<64xf32>, tensor<128xf32>, tensor<128xf32>, tensor<39x64xbf16>, tensor<64xbf16>, tensor<31x64xbf16>, tensor<31x64xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<128x64xbf16>, tensor<139x128xbf16>, tensor<2xui32>, tensor<2xui32>, tensor<768x768x128xf32>, tensor<768x384xf32>, tensor<768x447xbf16>, tensor<2xui32>, tensor<768x447xbf16>, tensor<768xi1>, tensor<768xi32>, tensor<768xi32>, tensor<768xi32>, tensor<768xi32>, tensor<768xi32>, tensor<768x2xi1>, tensor<768x2xi32>, tensor<7680x2xi1>, tensor<7680x2xi32>, tensor<4x768xi32>, tensor<4x768x24xi1>, tensor<4x768x24x3xf32>, tensor<16384x768xi1>, tensor<16384x768xi8>, tensor<16384x768xi8>) -> (tensor<i32>, tensor<4x64xf32>, tensor<4x64xf32>, tensor<4x64x64xbf16>, tensor<4x64x64xbf16>, tensor<4x128x8xbf16>, tensor<4x128xf32>, tensor<4x128xf32>, tensor<4x64x8x8xbf16>, tensor<4x64xf32>, tensor<4x64xf32>, tensor<4x64x512xbf16>, tensor<4x256x64xbf16>, tensor<4x128xbf16>, tensor<4x32x32x128xbf16>, tensor<4x64xf32>, tensor<4x64xf32>, tensor<4x64x32xbf16>, tensor<4x64x32xbf16>, tensor<4x128xf32>, tensor<4x128xf32>, tensor<4x128x128xbf16>, tensor<4x4x32x128xbf16>, tensor<4x128x128xbf16>, tensor<4x128x4xbf16>, tensor<4x4x32x128xbf16>, tensor<4x128x4x32xbf16>, tensor<4x128xf32>, tensor<4x128xf32>, tensor<4x128x128xbf16>, tensor<4x4x32x128xbf16>, tensor<4x128x128xbf16>, tensor<4x128x4xbf16>, tensor<4x4x32x128xbf16>, tensor<4x128x4x32xbf16>, tensor<4x128xf32>, tensor<4x128xf32>, tensor<4x128x1024xbf16>, tensor<4x512x128xbf16>, tensor<4x128xf32>, tensor<4x128xf32>, tensor<4x128x256xbf16>, tensor<4x128x128xbf16>, tensor<4x128xf32>, tensor<4x128xf32>, tensor<4x128x128xbf16>, tensor<4x128x256xbf16>, tensor<4x128xf32>, tensor<4x128xf32>, tensor<4x128x256xbf16>, tensor<4x128x128xbf16>, tensor<4x128xf32>, tensor<4x128xf32>, tensor<4x128x128xbf16>, tensor<4x128x256xbf16>, tensor<48x128xf32>, tensor<48x128xf32>, tensor<48x128x128xbf16>, tensor<48x4x32x128xbf16>, tensor<48x128x128xbf16>, tensor<48x128x4xbf16>, tensor<48x4x32x128xbf16>, tensor<48x128x4x32xbf16>, tensor<48x128xf32>, tensor<48x128xf32>, tensor<48x128x128xbf16>, tensor<48x4x32x128xbf16>, tensor<48x128x128xbf16>, tensor<48x128x4xbf16>, tensor<48x4x32x128xbf16>, tensor<48x128x4x32xbf16>, tensor<48x128xf32>, tensor<48x128xf32>, tensor<48x128x1024xbf16>, tensor<48x512x128xbf16>, tensor<48x384x384xbf16>, tensor<48x384x16x24xbf16>, tensor<48x384xf32>, tensor<48x384xf32>, tensor<48x16x24xbf16>, tensor<48x384x16x24xbf16>, tensor<48x384x384xbf16>, tensor<48x384x16x24xbf16>, tensor<48x128xf32>, tensor<48x128xf32>, tensor<48x128x16xbf16>, tensor<48x384xf32>, tensor<48x384xf32>, tensor<48x384x3072xbf16>, tensor<48x1536x384xbf16>, tensor<48x128xf32>, tensor<48x128xf32>, tensor<48x128x256xbf16>, tensor<48x128x128xbf16>, tensor<48x128xf32>, tensor<48x128xf32>, tensor<48x128x128xbf16>, tensor<48x128x256xbf16>, tensor<48x128xf32>, tensor<48x128xf32>, tensor<48x128x256xbf16>, tensor<48x128x128xbf16>, tensor<48x128xf32>, tensor<48x128xf32>, tensor<48x128x128xbf16>, tensor<48x128x256xbf16>, tensor<1x128xbf16>, tensor<447x64xbf16>, tensor<447x128xbf16>, tensor<34x64xbf16>, tensor<128x128xbf16>, tensor<128xf32>, tensor<128xf32>, tensor<384x384xbf16>, tensor<384xf32>, tensor<384xf32>, tensor<447x128xbf16>, tensor<447x384xbf16>, tensor<64x128xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x64xbf16>, tensor<2x4x16x64xbf16>, tensor<2x64x64xbf16>, tensor<2x64x4xbf16>, tensor<2x4x16x64xbf16>, tensor<2x64x4x16xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x64xbf16>, tensor<2x4x16x64xbf16>, tensor<2x64x64xbf16>, tensor<2x64x4xbf16>, tensor<2x4x16x64xbf16>, tensor<2x64x4x16xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x256xbf16>, tensor<2x128x64xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x128xbf16>, tensor<2x64x64xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x64xbf16>, tensor<2x64x128xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x128xbf16>, tensor<2x64x64xbf16>, tensor<2x64xf32>, tensor<2x64xf32>, tensor<2x64x64xbf16>, tensor<2x64x128xbf16>, tensor<64xf32>, tensor<64xf32>, tensor<128xf32>, tensor<128xf32>, tensor<39x64xbf16>, tensor<64xbf16>, tensor<31x64xbf16>, tensor<31x64xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<128x64xbf16>, tensor<139x128xbf16>, tensor<2xui32>, tensor<2xui32>, tensor<768x768x128xf32>, tensor<768x384xf32>, tensor<768x447xbf16>, tensor<2xui32>, tensor<768x447xbf16>, tensor<768xi1>, tensor<768xi32>, tensor<768xi32>, tensor<768xi32>, tensor<768xi32>, tensor<768xi32>, tensor<768x2xi1>, tensor<768x2xi32>, tensor<7680x2xi1>, tensor<7680x2xi32>, tensor<4x768xi32>, tensor<4x768x24xi1>, tensor<4x768x24x3xf32>, tensor<16384x768xi1>, tensor<16384x768xi8>, tensor<16384x768xi8>)
  state, val = jax.lax.fori_loop(lower, upper, pure_body_fun, init_val)
              ^

--------------------
For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.
